import requests
import json
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
import os
import io
import base64
import traceback
import hashlib
from urllib.parse import urlparse
# crawled_data_analyze_multimodel.py (ìƒë‹¨ ê·¼ì²˜)
from pathlib import Path

FILE_DIR = Path(__file__).resolve().parent  # ì´ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬

# This assumes you have a config.py file to load the API key.
# If not, you can assign the key directly.
try:
    from config import Config
except ImportError:
    # Create a dummy Config class if config.py doesn't exist
    class Config:
        upstage_api_key = os.environ.get("UPSTAGE_API_KEY", None)

@dataclass
class ProcessedContent:
    """ì²˜ë¦¬ëœ ì½˜í…ì¸  ê²°ê³¼"""
    original_title: str
    original_url: str
    content_type: str
    final_text: str
    processing_method: str
    image_analysis_results: Optional[List[Dict]] = None
    chunk_ready: bool = False
    error_message: str = ""

class ContentAnalyzer:
    """ì½˜í…ì¸  ë¶„ì„ ë° ì²˜ë¦¬ ì—ì´ì „íŠ¸"""

    def __init__(self, upstage_api_key: Optional[str] = None):
        self.upstage_api_key = upstage_api_key
        self.upstage_doc_url = "https://api.upstage.ai/v1/document-digitization"
        self.api_url = "https://api.upstage.ai/v1/solar/chat/completions"

        self.content_type_criteria = {
            "text_only": "ì´ë¯¸ì§€ 0ê°œ - í…ìŠ¤íŠ¸ë§Œ ìˆëŠ” ì½˜í…ì¸ ",
            "image_heavy": "í…ìŠ¤íŠ¸ 100ì ë¯¸ë§Œ + ì´ë¯¸ì§€ 1ê°œ ì´ìƒ - ì£¼ë¡œ ì´ë¯¸ì§€ë¡œ êµ¬ì„±",
            "mixed": "í…ìŠ¤íŠ¸ 100ì ì´ìƒ + ì´ë¯¸ì§€ 1ê°œ ì´ìƒ - í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ í˜¼í•©"
        }
        
        if self.upstage_api_key:
            self.headers = {
                'Authorization': f'Bearer {self.upstage_api_key}',
                'Content-Type': 'application/json'
            }
        else:
            self.headers = {}

    def select_essential_data(self, article_json: Dict) -> Dict:
        """ì „ì²´ JSONì—ì„œ í•„ìˆ˜ ì •ë³´ë§Œ ì„ ë³„"""
        selected = {
            "title": article_json.get("title", ""),
            "content_type": article_json.get("content_type", "unknown"),
            "content_type_criteria": self.content_type_criteria.get(
                article_json.get("content_type", "unknown"),
                "ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…"
            ),
            "link" : article_json.get("link",""),
            "text_content": article_json.get("text_content", ""),
            "text_length": article_json.get("text_length", 0),
            "image_count": article_json.get("image_count", 0),
            "images": article_json.get("images", [])
        }
        print(f"ì„ ë³„ëœ ë°ì´í„°: {selected['title']} ({selected['content_type']})")
        return selected

    def _document_parse_file(self, fp: str) -> str:
        """Upstage Document Parseë¡œ ì´ë¯¸ì§€/ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ"""
        headers = {"Authorization": f"Bearer {self.upstage_api_key}"}
        data = {"model": "document-parse", "output_formats": '["text"]'}
        with open(fp, "rb") as f:
            files = {"document": (os.path.basename(fp), f)}
            resp = requests.post(self.upstage_doc_url, headers=headers, files=files, data=data, timeout=60)
        resp.raise_for_status()
        j = resp.json()
        container = j.get("content") or j.get("result") or {}
        text = container.get("text") or container.get("plain_text") or ""
        if not text and isinstance(container.get("pages"), list):
            text = "\n".join(p.get("text", "") for p in container["pages"])
        return (text or "").strip()

    def _download_and_parse_images(self, images, save_dir : str | Path = "temp_images" , max_chars=1200):
        """ì´ë¯¸ì§€ URLë“¤ì„ ë¡œì»¬ì— ì €ì¥í•˜ê³ , Document Parseë¡œ í…ìŠ¤íŠ¸ë¥¼ ë½‘ì•„ í•©ì³ì„œ ë°˜í™˜"""
        if not images:
            return "(ì´ë¯¸ì§€ ì—†ìŒ)", [], []

        save_dir = Path(save_dir)
        
        if not save_dir.is_absolute():
            # ìƒëŒ€ ê²½ë¡œë¡œ ë“¤ì–´ì˜¤ë©´ íŒŒì¼ ê¸°ì¤€ìœ¼ë¡œ ë¶™ì¸ë‹¤
            save_dir = FILE_DIR / save_dir

        save_dir.mkdir(parents=True, exist_ok=True)

        combined_texts, local_paths, analysis_results = [], [], []

        for i, img_data in enumerate(images, start=1):
            img_url = img_data.get("full_url")
            if not img_url:
                combined_texts.append(f"[ì´ë¯¸ì§€ {i}] (URL ëˆ„ë½)")
                continue

            ext = os.path.splitext(urlparse(img_url).path)[1] or ".jpg"
            name = f"img_{i}_{hashlib.md5(img_url.encode()).hexdigest()[:8]}{ext}"
            local_fp = os.path.join(save_dir, name)

            try:
                r = requests.get(img_url, timeout=30)
                r.raise_for_status()
                with open(local_fp, "wb") as f:
                    f.write(r.content)
                local_paths.append(local_fp)

                text = self._document_parse_file(local_fp) or "(í…ìŠ¤íŠ¸ ì¶”ì¶œ ì—†ìŒ)"
                text = text.replace("\r", " ").strip()
                if len(text) > max_chars:
                    text = text[:max_chars] + "â€¦(ìƒëµ)"

                combined_texts.append(f"[ì´ë¯¸ì§€ {i} ë‚´ìš©]\n{text}")
                analysis_results.append({"image_url": img_url, "extracted_text": text})

            except Exception as e:
                error_msg = f"[ì´ë¯¸ì§€ {i}] (ë‹¤ìš´ë¡œë“œ/íŒŒì‹± ì‹¤íŒ¨: {e})"
                combined_texts.append(error_msg)
                analysis_results.append({"image_url": img_url, "error": str(e)})

        return "\n\n".join(combined_texts), local_paths, analysis_results
        
    def create_unified_prompt(self, data: Dict) -> tuple[str, list | None]:
        """í†µí•© í”„ë¡¬í”„íŠ¸ ìƒì„± (OCR ê²°ê³¼ì™€ í•¨ê»˜)"""
        image_text_block = "(ì´ë¯¸ì§€ ì—†ìŒ)"
        image_analysis_results = None
        
        if self.upstage_api_key and data.get("images"):
            try:
                image_text_block, _, image_analysis_results = self._download_and_parse_images(data["images"])
            except Exception as e:
                print(f"ì´ë¯¸ì§€ íŒŒì‹± ì‹¤íŒ¨(ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}")
                image_text_block = f"(ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e})"

        prompt = f"""ë‹¹ì‹ ì€ ì›¹ì‚¬ì´íŠ¸ ê²Œì‹œê¸€ì„ ë¶„ì„í•´ì„œ ê²€ìƒ‰ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ê°€ì´ë“œë¼ì¸ê³¼ ê²Œì‹œê¸€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‚´ìš©ì„ ë³€í™˜í•´ì£¼ì„¸ìš”.

=== ì½˜í…ì¸  íƒ€ì…ë³„ ì²˜ë¦¬ ê°€ì´ë“œ ===
- text_only: í…ìŠ¤íŠ¸ë§Œ ìˆëŠ” ì½˜í…ì¸  â†’ í•µì‹¬ ë‚´ìš© ìš”ì•½/ì •ë¦¬
- image_heavy: ì£¼ë¡œ ì´ë¯¸ì§€ë¡œ êµ¬ì„±ëœ ì½˜í…ì¸  â†’ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ì„¤ëª… í…ìŠ¤íŠ¸ë¡œ ë³€í™˜, ì¤‘ìš” í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í¬í•¨
- mixed: í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ í˜¼í•© â†’ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ê²°í•©í•˜ì—¬ ì¢…í•©ì ìœ¼ë¡œ ì„¤ëª…

=== ë¶„ì„í•  ê²Œì‹œê¸€ ì •ë³´ ===
ì œëª©: {data['title']}
ì½˜í…ì¸  íƒ€ì…: {data['content_type']} ({data.get('content_type_criteria')})
í…ìŠ¤íŠ¸ ë‚´ìš©:
{data['text_content'] if data.get('text_content') else '(í…ìŠ¤íŠ¸ ì—†ìŒ)'}

ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ ë‚´ìš©:
{image_text_block}

=== ìš”ì²­ì‚¬í•­ ===
1. ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ê²Œì‹œê¸€ì˜ í•µì‹¬ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
2. ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ ê·¸ ë‚´ìš©ê³¼ ì˜ë¯¸(ì¤‘ìš” ìˆ˜ì¹˜, ì§€ëª…, ì¸ë¬¼, í–‰ì‚¬ëª… ë“±)ë¥¼ ë³¸ë¬¸ì— ë…¹ì—¬ë‚´ì„¸ìš”.
3. ë§ˆì§€ë§‰ì— ê²€ìƒ‰ì— ë„ì›€ ë  í‚¤ì›Œë“œë¥¼ 5ê°œ ì´ìƒ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì œì‹œí•´ì£¼ì„¸ìš”. (ì˜ˆ: í‚¤ì›Œë“œ: ë¶€ì‚°, ì™¸êµ­ì¸, ì§€ì›, í–‰ì‚¬, ì•ˆë‚´)

ê²°ê³¼ëŠ” ìœ„ ìš”ì²­ì‚¬í•­ì„ ë°˜ì˜í•œ ìµœì¢… í…ìŠ¤íŠ¸ë§Œ ìƒì„±í•´ì£¼ì„¸ìš”.
"""
        return prompt, image_analysis_results

    def fallback_processing(self, data: Dict) -> ProcessedContent:
        """Upstage Solar API ì‚¬ìš© ë¶ˆê°€ ì‹œ ëŒ€ì²´ ì²˜ë¦¬"""
        print("ğŸ“ ëŒ€ì²´ ì²˜ë¦¬ ë°©ì‹ ì‚¬ìš© ì¤‘...")
        final_text = f"ì œëª©: {data['title']}\n\në‚´ìš©:\n{data['text_content']}"
        return ProcessedContent(
            original_title=data['title'],
            original_url=data['images'][0]['full_url'] if data['images'] else None,
            content_type=data['content_type'],
            final_text=final_text.strip(),
            processing_method="fallback_rule_based",
            chunk_ready=True
        )

    def analyze_content_with_llm(self, selected_data: Dict) -> ProcessedContent:
        """í†µí•© Upstage Solar ì—ì´ì „íŠ¸ê°€ ëª¨ë“  íƒ€ì…ì„ íŒë‹¨í•´ì„œ ì²˜ë¦¬"""
        print(f"ğŸ¤– Upstage Solar ì—ì´ì „íŠ¸ë¡œ ì²˜ë¦¬ ì¤‘: {selected_data['title']}")
        if not self.upstage_api_key:
            print("key is not proper")
            return self.fallback_processing(selected_data)

        prompt, image_analysis_results = self.create_unified_prompt(selected_data)
        
        try:
            payload = {
                "model": "solar-1-mini-chat",
                "messages": [
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì›¹ì‚¬ì´íŠ¸ ê²Œì‹œê¸€ì„ ë¶„ì„í•´ì„œ ê²€ìƒ‰ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 1024, "temperature": 0.2
            }
            response = requests.post(self.api_url, headers=self.headers, json=payload, timeout=90)
            response.raise_for_status()
            result = response.json()

            if 'choices' in result and result['choices']:
                final_text = result['choices'][0]['message']['content'].strip()
                print(f"Solar API ì²˜ë¦¬ ì™„ë£Œ: {len(final_text)} ë¬¸ì")
                return ProcessedContent(
                    original_title=selected_data['title'],
                    original_url=selected_data['link'],
                    content_type=selected_data['content_type'],
                    final_text=final_text,
                    processing_method="upstage_solar_agent",
                    image_analysis_results=image_analysis_results,
                    chunk_ready=True
                )
            else:
                print("Solar API ì‘ë‹µì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤")
                return self.fallback_processing(selected_data)

        except requests.exceptions.RequestException as e:
            print(f"Solar API ìš”ì²­ ì‹¤íŒ¨: {e}")
            return self.fallback_processing(selected_data)
        except Exception as e:
            print(f"Solar API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return self.fallback_processing(selected_data)

    def process_articles_batch(self, articles_json: List[Dict]) -> List[ProcessedContent]:
        """ì—¬ëŸ¬ ê²Œì‹œê¸€ì„ ì¼ê´„ ì²˜ë¦¬"""
        print(f"=== ì¼ê´„ ì²˜ë¦¬ ì‹œì‘: {len(articles_json)}ê°œ ê²Œì‹œê¸€ ===")
        processed_results = []
        for i, article in enumerate(articles_json):
            print(f"\n--- ê²Œì‹œê¸€ {i+1}/{len(articles_json)} ì²˜ë¦¬ ì¤‘ ---")
            selected_data = self.select_essential_data(article)
            result = self.analyze_content_with_llm(selected_data)
            processed_results.append(result)
            if self.upstage_api_key:
                time.sleep(1) # API Rate Limit ë°©ì§€
        print(f"\n=== ì¼ê´„ ì²˜ë¦¬ ì™„ë£Œ: {len(processed_results)}ê°œ ì™„ë£Œ ===")
        return processed_results

    def save_processed_results(self, results: List[ProcessedContent], filename: str):
        """ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ë° í†µê³„ ì¶œë ¥"""
        output_data = [result.__dict__ for result in results]
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        print(f"ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename}")
        self.show_processing_stats(results)

    def show_processing_stats(self, results: List[ProcessedContent]):
        """ì²˜ë¦¬ ê²°ê³¼ í†µê³„"""
        total = len(results)
        success = sum(1 for r in results if r.chunk_ready)
        
        print("\n=== ì²˜ë¦¬ ê²°ê³¼ í†µê³„ ===")
        print(f"ì´ ì²˜ë¦¬: {total}ê°œ, ì„±ê³µ: {success}ê°œ, ì‹¤íŒ¨: {total - success}ê°œ")
        
        methods = {}
        for result in results:
            methods[result.processing_method] = methods.get(result.processing_method, 0) + 1
        print("\nì²˜ë¦¬ ë°©ë²•ë³„ ë¶„í¬:")
        for method, count in methods.items():
            print(f"  {method}: {count}ê°œ")

# --------------------------------------------------------------------
# 1. í•µì‹¬ ì‹¤í–‰ ë¡œì§ì„ ì´ í•¨ìˆ˜ ì•ˆì— ëª¨ë‘ ë„£ìŠµë‹ˆë‹¤.
# --------------------------------------------------------------------
def run_analysis_and_save(input_filename: str, output_filename: str, api_key: Optional[str]):
    """
    ì¶”ì¶œëœ ê²Œì‹œê¸€ JSONì„ ì½ì–´ ë¶„ì„í•˜ê³ , ì²˜ë¦¬ëœ ê²°ê³¼ë¥¼ ìƒˆ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    print("=" * 50)
    print("ì¶”ì¶œëœ ê²Œì‹œê¸€ ë¶„ì„ ë° ì²˜ë¦¬ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    print("=" * 50)

    analyzer = ContentAnalyzer(upstage_api_key=api_key)
    
    # --- ì—¬ê¸°ê°€ í•µì‹¬ ---
    # ì´ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì´ ìˆëŠ” 'routers' í´ë”ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # ìœ„ ê²½ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì…ë ¥/ì¶œë ¥ íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œë¥¼ ë§Œë“­ë‹ˆë‹¤.
    input_filepath = os.path.join(script_dir, input_filename)
    output_filepath = os.path.join(script_dir, output_filename)
    # ------------------
    
    try:
        # ìˆ˜ì •ëœ ê²½ë¡œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        with open(input_filepath, 'r', encoding='utf-8') as f:
            articles_data = json.load(f)
        
        print(f"ë¶ˆëŸ¬ì˜¨ ê²Œì‹œê¸€ ìˆ˜: {len(articles_data)} (from {input_filepath})")
        
        processed_results = analyzer.process_articles_batch(articles_data)
        # ìˆ˜ì •ëœ ê²½ë¡œì— ì €ì¥í•©ë‹ˆë‹¤.
        analyzer.save_processed_results(processed_results, output_filepath)

    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: ì…ë ¥ íŒŒì¼ '{input_filepath}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("í¬ë¡¤ë§ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        print(f"\n[ì˜¤ë¥˜] ì „ì²´ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        traceback.print_exc()

# if __name__ == "__main__": ë¶€ë¶„ë„ base_path ì—†ì´ í˜¸ì¶œí•˜ë„ë¡ ìˆ˜ì •í•©ë‹ˆë‹¤.
if __name__ == "__main__":
    config = Config()
    upstage_key = config.upstage_api_key
    
    run_analysis_and_save(
        input_filename="extracted_articles.json",
        output_filename="processed_content.json",
        api_key=upstage_key
    )